[["index.html", "Encyclopedia of Quantitative Methods in R, vol. 3: Testing Mean Differences Welcome Blocked Notes Code and Output The Authors", " Encyclopedia of Quantitative Methods in R, vol. 3: Testing Mean Differences Sarah Schwartz &amp; Tyson Barrett Last updated: 2022-11-01 Welcome Backgroup and links to other volumes of this encyclopedia may be found at the Encyclopedia’s Home Website. Blocked Notes Thoughout all the eBooks in this encyclopedia, several small secitons will be blocked out in the following ways: These blocks denote an area UNDER CONSTRUCTION, so check back often. This massive undertaking started during the summer of 2018 and is far from complete. The outline of seven volumes is given above despite any one being complete. Feedback is welcome via either author’s email. These blocks denote something EXTREMELY IMPORTANT. Do NOT skip these notes as they will be used very sparingly. These blocks denote something to DOWNLOAD. This may include software installations, example datasets, or notebook code files. These blocks denote something INTERESTING. These point out information we found of interest or added value. These blocks denote LINKS to other websites. This may include instructional video clips, articles, or blog posts. We are all about NOT re-creating the wheel. If somebody else has described or illustrated a topic well, we celebrate it! Code and Output This is how \\(R\\) code is shown: 1 + 1 This is what the output of the \\(R\\) code above will look: [1] 2 The Authors Dr. Sarah Schwartz Dr. Tyson Barrett www.SarahSchwartzStats.com www.TysonBarrett.com Sarah.Schwartz@usu.edu Tyson.Barrett@usu.edu Statistical Consulting Studio Data Science and Discover Unit Why choose R ? Check it out: an article from Fall 2016… No more excuses: R is better than SPSS for psychology undergrads, and students agree FYI This entire encyclopedia is written in \\(R Markdown\\), using \\(R Studio\\) as the text editor and the bookdown package to turn a collection of markdown documents into a coherent whole. The book’s source code is hosted on GitHub. If you notice typos or other issues, feel free to email either of the authors. This work is licensed under the Attribution-NonCommercial-NoDerivatives 4.0 International License. "],["ihnoprep.html", "1 Intro: Ihno’s Experiemnt 1.1 Background of Data 1.2 Import &amp; Wrangle the Data 1.3 Overview", " 1 Intro: Ihno’s Experiemnt library(tidyverse) # super helpful everything! library(haven) # inporting SPSS, SAS, &amp; Stata data files library(psych) # lots of nice tidbits 1.1 Background of Data (epse4?): has made the data from his textbook “Explaining Spychological Statistics, 4th edition” available on his website The data come from a hypothetical study performed by Ihno (pronounced “Eee-know”), an advanced doctoral student, who was the teaching assistant (TA) for several sections of a statistics course. The 100 participants in the data set are the students who were enrolled in Ihno’s sections, and voluntarily consented to be in her study, which was approved by the appropriate review board at her hypothetical school. Her data were collected on two different days. On the ﬁrst day of classes, the students who came to one of Ihno’s sections ﬁlled in a brief background questionnaire on which they provided contact information, some qualitative data (gender, undergrad major, why they had enrolled in statistics (reason), and whether they have a habit of drinking coffee), and some quantitative data (number of math courses already completed (prevmath), the score they received on a diagnostic math background quiz they were all required to take before registering for statistics mathquiz, and a rating of their math phobia on a scale from 0 to 10). You will see that, due to late registration and other factors, not all of Ihno’s students took the diagnostic math background quiz. The rest of Ihno’s data were collected as part of an experiment that she conducted during her recitation sessions on one day in the middle of the semester. (The one exception is that her students took a regular 10 question quiz the week before her experiment (statquiz), and she decided to add those scores to her data set.) At the beginning of the experiment, Ihno explained how each student could take his or her own pulse. She then provided a half-minute interval during which they counted the number of beats, and then wrote down twice that number as their heart rate (hr_base) in beats per minute (bpm). Then, each student reported how many cups of coffee they had consumed since waking up that morning (num_cups), and ﬁlled out an anxiety questionnaire consisting of 10 items, each rated (0 to 4) on a 5-point Likertscale. Total scores could range from 0 to 40, and provided a measure of baseline anxiety (anx_base). Next, Ihno announced a pop quiz. She handed out a page containing 11 multiple-choice statistics questions on material covered during the preceding two weeks, and asked the students to keep this page face down while taking and recording their pulse (hr_pre) and ﬁlling out a anxiety questionnaire (anx_pre). Then Ihno told the students they had 15 minutes to take the fairly difﬁcult quiz. She also told them that the ﬁrst 10 questions were worth 1 point each but that the 11th question was worth 3 points of extra credit. Ihno’s experimental manipulation consisted of varying the difﬁculty of the 11th question. Twenty-ﬁve quizzes were distributed at each level of difﬁculty of the ﬁnal question: easy, moderate, difﬁcult, and impossible to solve (exp_cond). After the quizzes were collected, Ihno asked the students to provide heart rate and anxiety data one more time (hr_post, anx_post). Finally, Ihno explained the experiment, adding that the 11th quiz question would not be scored and that, although the students would get back their quizzes with their score for the ﬁrst 10 items (statquiz), that score would not inﬂuence their grade for the statistics course. You can use a file’s link to read data directly off a website 1.2 Import &amp; Wrangle the Data The Cancer dataset is saved in SPSS format, which is evident from the .sav ending on the file name. The haven package is downloaded as part of the tidyverse set of packages, but is not automatically loaded. It must have its own library() function call (see above). The haven::read_spss() function works very simarly to the readxl::read_excel() function we used last chapter (Wickham, Miller, and Smith 2022). Make sure the dataset is saved in the same folder as this file Make sure the that folder is the working directory data_ihno &lt;- haven::read_spss(&quot;https://github.com/CEHS-research/PSY-6600_students/raw/master/Data/Ihno_dataset.sav&quot;) %&gt;% dplyr::rename_all(tolower) %&gt;% dplyr::mutate(genderF = factor(gender, levels = c(1, 2), labels = c(&quot;Female&quot;, &quot;Male&quot;))) %&gt;% dplyr::mutate(majorF = factor(major, levels = c(1, 2, 3, 4,5), labels = c(&quot;Psychology&quot;, &quot;Premed&quot;, &quot;Biology&quot;, &quot;Sociology&quot;, &quot;Economics&quot;))) %&gt;% dplyr::mutate(reasonF = factor(reason, levels = c(1, 2, 3), labels = c(&quot;Program requirement&quot;, &quot;Personal interest&quot;, &quot;Advisor recommendation&quot;))) %&gt;% dplyr::mutate(exp_condF = factor(exp_cond, levels = c(1, 2, 3, 4), labels = c(&quot;Easy&quot;, &quot;Moderate&quot;, &quot;Difficult&quot;, &quot;Impossible&quot;))) %&gt;% dplyr::mutate(coffeeF = factor(coffee, levels = c(0, 1), labels = c(&quot;Not a regular coffee drinker&quot;, &quot;Regularly drinks coffee&quot;))) 1.3 Overview 1.3.1 Dimentions (size) of the dataset dim(data_ihno) [1] 100 23 1.3.2 Variable Names names(data_ihno) [1] &quot;sub_num&quot; &quot;gender&quot; &quot;major&quot; &quot;reason&quot; &quot;exp_cond&quot; &quot;coffee&quot; [7] &quot;num_cups&quot; &quot;phobia&quot; &quot;prevmath&quot; &quot;mathquiz&quot; &quot;statquiz&quot; &quot;exp_sqz&quot; [13] &quot;hr_base&quot; &quot;hr_pre&quot; &quot;hr_post&quot; &quot;anx_base&quot; &quot;anx_pre&quot; &quot;anx_post&quot; [19] &quot;genderF&quot; &quot;majorF&quot; &quot;reasonF&quot; &quot;exp_condF&quot; &quot;coffeeF&quot; 1.3.3 Quick Glimpse tibble::glimpse(data_ihno) Rows: 100 Columns: 23 $ sub_num &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1… $ gender &lt;dbl+lbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… $ major &lt;dbl+lbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… $ reason &lt;dbl+lbl&gt; 3, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3,… $ exp_cond &lt;dbl+lbl&gt; 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 3, 4, 4, 4, 4, 4,… $ coffee &lt;dbl+lbl&gt; 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1,… $ num_cups &lt;dbl&gt; 0, 0, 0, 0, 1, 1, 0, 2, 0, 2, 1, 0, 1, 2, 3, 0, 0, 3, 2, 1, … $ phobia &lt;dbl&gt; 1, 1, 4, 4, 10, 4, 4, 4, 4, 5, 5, 4, 7, 4, 3, 8, 4, 5, 0, 4,… $ prevmath &lt;dbl&gt; 3, 4, 1, 0, 1, 1, 2, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 3, 1, … $ mathquiz &lt;dbl+lbl&gt; 43, 49, 26, 29, 31, 20, 13, 23, 38, NA, 29, 32, 18, NA, … $ statquiz &lt;dbl&gt; 6, 9, 8, 7, 6, 7, 3, 7, 8, 7, 8, 8, 1, 5, 8, 3, 8, 7, 10, 7,… $ exp_sqz &lt;dbl&gt; 7, 11, 8, 8, 6, 6, 4, 7, 7, 6, 10, 7, 3, 4, 6, 1, 7, 4, 9, 7… $ hr_base &lt;dbl&gt; 71, 73, 69, 72, 71, 70, 71, 77, 73, 78, 74, 73, 73, 72, 72, … $ hr_pre &lt;dbl&gt; 68, 75, 76, 73, 83, 71, 70, 87, 72, 76, 72, 74, 76, 83, 74, … $ hr_post &lt;dbl&gt; 65, 68, 72, 78, 74, 76, 66, 84, 67, 74, 73, 74, 78, 77, 68, … $ anx_base &lt;dbl&gt; 17, 17, 19, 19, 26, 12, 12, 17, 20, 20, 21, 32, 19, 18, 21, … $ anx_pre &lt;dbl&gt; 22, 19, 14, 13, 30, 15, 16, 19, 14, 24, 25, 35, 23, 27, 27, … $ anx_post &lt;dbl&gt; 20, 16, 15, 16, 25, 19, 17, 22, 17, 19, 22, 33, 20, 28, 22, … $ genderF &lt;fct&gt; Female, Female, Female, Female, Female, Female, Female, Fema… $ majorF &lt;fct&gt; Psychology, Psychology, Psychology, Psychology, Psychology, … $ reasonF &lt;fct&gt; Advisor recommendation, Personal interest, Program requireme… $ exp_condF &lt;fct&gt; Easy, Easy, Easy, Easy, Easy, Moderate, Moderate, Moderate, … $ coffeeF &lt;fct&gt; Regularly drinks coffee, Not a regular coffee drinker, Not a… 1.3.4 Top and Bottom Rows psych::headTail(data_ihno) sub_num gender major reason exp_cond coffee num_cups phobia prevmath mathquiz 1 1 1 1 3 1 1 0 1 3 43 2 2 1 1 2 1 0 0 1 4 49 3 3 1 1 1 1 0 0 4 1 26 4 4 1 1 1 1 0 0 4 0 29 5 ... ... ... ... ... ... ... ... ... ... 6 97 2 5 2 3 0 0 0 2 28 7 98 2 5 2 3 0 0 2 2 38 8 99 2 5 2 4 1 1 1 4 41 9 100 2 5 1 2 0 0 2 2 39 statquiz exp_sqz hr_base hr_pre hr_post anx_base anx_pre anx_post genderF 1 6 7 71 68 65 17 22 20 Female 2 9 11 73 75 68 17 19 16 Female 3 8 8 69 76 72 19 14 15 Female 4 7 8 72 73 78 19 13 16 Female 5 ... ... ... ... ... ... ... ... &lt;NA&gt; 6 8 9 70 66 65 17 12 13 Male 7 9 10 65 65 69 18 14 19 Male 8 8 8 72 68 73 17 11 18 Male 9 7 7 70 70 64 17 11 14 Male majorF reasonF exp_condF coffeeF 1 Psychology Advisor recommendation Easy Regularly drinks coffee 2 Psychology Personal interest Easy Not a regular coffee drinker 3 Psychology Program requirement Easy Not a regular coffee drinker 4 Psychology Program requirement Easy Not a regular coffee drinker 5 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; 6 Economics Personal interest Difficult Not a regular coffee drinker 7 Economics Personal interest Difficult Not a regular coffee drinker 8 Economics Personal interest Impossible Regularly drinks coffee 9 Economics Program requirement Moderate Not a regular coffee drinker "],["cancerprep.html", "2 Intro: Cancer Experiemnt 2.1 Source of Data 2.2 Description of the Study 2.3 Variables 2.4 Import Data 2.5 Wrangle Data 2.6 Overview", " 2 Intro: Cancer Experiemnt library(tidyverse) # super helpful everything! library(haven) # inporting SPSS, SAS, &amp; Stata data files library(psych) # lots of nice tidbits 2.1 Source of Data Mid-Michigan Medical Center, Midland, Michigan, 1999: A study of oral condition of cancer patients. 2.2 Description of the Study The data set contains part of the data for a study of oral condition of cancer patients conducted at the Mid-Michigan Medical Center. The oral conditions of the patients were measured and recorded at the initial stage, at the end of the second week, at the end of the fourth week, and at the end of the sixth week. The variables age, initial weight and initial cancer stage of the patients were recorded. Patients were divided into two groups at random: One group received a placebo and the other group received aloe juice treatment. Sample size n = 25 patients with neck cancer. The treatment is Aloe Juice. 2.3 Variables ID patient identification number trt treatment group 0 placebo 1 aloe juice age patient’s age, in years weightin patient’s weight (pounds) at the initial stage stage initial cancer stage coded 1 through 4 totalcin oral condition at the initial stage totalcw2 oral condition at the end of week 2 totalcw4 oral condition at the end of week 4 totalcw6 oral condition at the end of week 6 2.4 Import Data The Cancer dataset is saved in SPSS format, which is evident from the .sav ending on the file name. The haven package is downloaded as part of the tidyverse set of packages, but is not automatically loaded. It must have its own library() function call (see above). The haven::read_spss() function works very simarly to the readxl::read_excel() function we used last chapter (Wickham, Miller, and Smith 2022). Make sure the dataset is saved in the same folder as this file Make sure the that folder is the working directory cancer_raw &lt;- haven::read_spss(&quot;https://github.com/CEHS-research/PSY-6600_students/raw/master/Data/Cancer.sav&quot;) tibble::glimpse(cancer_raw) Rows: 25 Columns: 9 $ ID &lt;dbl&gt; 1, 5, 6, 9, 11, 15, 21, 26, 31, 35, 39, 41, 45, 2, 12, 14, 16… $ TRT &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1… $ AGE &lt;dbl&gt; 52, 77, 60, 61, 59, 69, 67, 56, 61, 51, 46, 65, 67, 46, 56, 4… $ WEIGHIN &lt;dbl&gt; 124.0, 160.0, 136.5, 179.6, 175.8, 167.6, 186.0, 158.0, 212.8… $ STAGE &lt;dbl&gt; 2, 1, 4, 1, 2, 1, 1, 3, 1, 1, 4, 1, 1, 2, 4, 1, 2, 1, 4, 2, 1… $ TOTALCIN &lt;dbl&gt; 6, 9, 7, 6, 6, 6, 6, 6, 6, 6, 7, 6, 8, 7, 6, 4, 6, 6, 12, 5, … $ TOTALCW2 &lt;dbl&gt; 6, 6, 9, 7, 7, 6, 11, 11, 9, 4, 8, 6, 8, 16, 10, 6, 11, 7, 11… $ TOTALCW4 &lt;dbl&gt; 6, 10, 17, 9, 16, 6, 11, 15, 6, 8, 11, 9, 9, 9, 11, 8, 11, 6,… $ TOTALCW6 &lt;dbl&gt; 7, 9, 19, 3, 13, 11, 10, 15, 8, 7, 11, 6, 10, 10, 9, 7, 14, 6… 2.5 Wrangle Data cancer_clean &lt;- cancer_raw %&gt;% dplyr::rename_all(tolower) %&gt;% dplyr::mutate(id = factor(id)) %&gt;% dplyr::mutate(trt = factor(trt, labels = c(&quot;Placebo&quot;, &quot;Aloe Juice&quot;))) %&gt;% dplyr::mutate(stage = factor(stage)) 2.6 Overview 2.6.1 Dimentions (size) of the dataset dim(cancer_clean) [1] 25 9 2.6.2 Variable Names names(cancer_clean) [1] &quot;id&quot; &quot;trt&quot; &quot;age&quot; &quot;weighin&quot; &quot;stage&quot; &quot;totalcin&quot; &quot;totalcw2&quot; [8] &quot;totalcw4&quot; &quot;totalcw6&quot; 2.6.3 Quick Glimpse tibble::glimpse(cancer_clean) Rows: 25 Columns: 9 $ id &lt;fct&gt; 1, 5, 6, 9, 11, 15, 21, 26, 31, 35, 39, 41, 45, 2, 12, 14, 16… $ trt &lt;fct&gt; Placebo, Placebo, Placebo, Placebo, Placebo, Placebo, Placebo… $ age &lt;dbl&gt; 52, 77, 60, 61, 59, 69, 67, 56, 61, 51, 46, 65, 67, 46, 56, 4… $ weighin &lt;dbl&gt; 124.0, 160.0, 136.5, 179.6, 175.8, 167.6, 186.0, 158.0, 212.8… $ stage &lt;fct&gt; 2, 1, 4, 1, 2, 1, 1, 3, 1, 1, 4, 1, 1, 2, 4, 1, 2, 1, 4, 2, 1… $ totalcin &lt;dbl&gt; 6, 9, 7, 6, 6, 6, 6, 6, 6, 6, 7, 6, 8, 7, 6, 4, 6, 6, 12, 5, … $ totalcw2 &lt;dbl&gt; 6, 6, 9, 7, 7, 6, 11, 11, 9, 4, 8, 6, 8, 16, 10, 6, 11, 7, 11… $ totalcw4 &lt;dbl&gt; 6, 10, 17, 9, 16, 6, 11, 15, 6, 8, 11, 9, 9, 9, 11, 8, 11, 6,… $ totalcw6 &lt;dbl&gt; 7, 9, 19, 3, 13, 11, 10, 15, 8, 7, 11, 6, 10, 10, 9, 7, 14, 6… 2.6.4 Top and Bottom Rows psych::headTail(cancer_clean) id trt age weighin stage totalcin totalcw2 totalcw4 totalcw6 1 1 Placebo 52 124 2 6 6 6 7 2 5 Placebo 77 160 1 9 6 10 9 3 6 Placebo 60 136.5 4 7 9 17 19 4 9 Placebo 61 179.6 1 6 7 9 3 5 &lt;NA&gt; &lt;NA&gt; ... ... &lt;NA&gt; ... ... ... ... 6 42 Aloe Juice 73 181.5 0 8 11 16 &lt;NA&gt; 7 44 Aloe Juice 67 187 1 5 7 7 7 8 50 Aloe Juice 60 164 2 6 8 16 &lt;NA&gt; 9 58 Aloe Juice 54 172.8 4 7 8 10 8 "],["one-sample-t-test-for-the-mean.html", "3 ONE SAMPLE t-TEST: for the MEAN 3.1 Exploratory Data Analysis: i.e. the eyeball method 3.2 Assumptions 3.3 Inference 3.4 Inho example", " 3 ONE SAMPLE t-TEST: for the MEAN Using the t.test() function library(psych) # lots of nice tidbits library(car) # Compantion 3.1 Exploratory Data Analysis: i.e. the eyeball method Is the baseline weight more than 165 pounds? 3.1.1 Mean and SD cancer_clean %&gt;% furniture::table1(weighin, na.rm = FALSE) ─────────────────────────── Mean/Count (SD/%) n = 25 weighin 178.3 (32.0) ─────────────────────────── 32 / sqrt(25) [1] 6.4 Since the stadard deviation (\\(s_X\\)) is 32.0, the standard error for the mean (SEM = SE = \\(s_{\\overline{X}}\\)) is 6.4. So even though the observed average of 178.3 is a higher number than 165, it may or may not we statistically significant. 3.2 Assumptions 3.2.1 Random Sampling The Sample was drawn at random (at least as representative as possible) Nothing can be done to fix NON-representative samples! Can not for with any statistically test 3.2.2 Normality A variable is said to follow the normal distribution if it resembles the normal curve. Specifically it is symetrical, unimodal, and bell shaped. The continuous variable has a NORMAL distribution in BOTH populations Not as important if the sample is large (Central Limit Theorem) IF the sample is far from normal &amp;/or small, might want to use a different method Options to judging normality: Visualization of each sample’s distribution Stacked histograms, but is sensitive to binning choices (number or width) Side-by-side boxplots, shows median instead of mean as central line Seperate QQ plots (straight \\(45^\\circ\\) line), but is sensitive to outliers! Calculate Skewness and Kurtosis Divided each value by its standard error (SE) A result \\(\\gt \\pm 2\\) indicates issues Formal Inferencial Tests for Normality Null-hypothesis: population is normally distributed A \\(p \\lt .05\\) ???indicate snon-normality For smaller samples, use Shapiro-Wilk’s Test For larger samples, use Kolmogorov-Smirnov’s Test cancer_clean %&gt;% ggplot(aes(weighin)) + geom_histogram(binwidth = 12) + geom_vline(xintercept = 165, # Add a thick red line at the grand mean of 165 pounds color = &quot;red&quot;, size = 1) The histogram is not truely normal, but it is fairly unimodal and somewhat bell shaped. There are mild concerns regarding the values above the mean. cancer_clean %&gt;% ggplot(aes(sample = weighin)) + # make sure to include &quot;sample = &quot; geom_qq() + # layer on the dots stat_qq_line() # layer on the line The Q-Q Plot displays a fairly linear pattern, but there are mild concerns at the highter values. cancer_clean %&gt;% dplyr::select(age, weighin) %&gt;% # we have to select MORE than one variable psych::describe() vars n mean sd median trimmed mad min max range skew age 1 25 59.64 12.93 60.0 59.95 11.86 27 86.0 59.0 -0.31 weighin 2 25 178.28 31.98 172.8 176.57 21.05 124 261.4 137.4 0.73 kurtosis se age -0.01 2.59 weighin 0.07 6.40 The skew is \\(0.73\\) which is close to \\(1\\), but the kurtosis is \\(0.07\\) which is NOT close to \\(1\\). This reflects that the distribution is fairly symetrical, but more spread out and not as peaked as a truely normal distribution. cancer_clean %&gt;% dplyr::pull(weighin) %&gt;% # extract the continuous variable shapiro.test() # test for normality (from base R) Shapiro-Wilk normality test data: . W = 0.93899, p-value = 0.1403 The Shapiro-Wilk’s test yielded NO evidence that weight is not normaly distributed at baseline, \\(W = .939, p = .140\\),. 3.3 Inference Formal Statistical Test: t-Test for Difference in Independent Group Means Use the t.test() funtion for a single sample. Before you can run the t Test, you must seperate out or ‘PULL’ your variable out of the dataset. Use the dplyr::pull(continuous_variable)step befor running the t Test Inside the funtion you need to specify one option: the null-hypothesis value: mu = ## (replace with your number) You MAY need/want to specify some or all of the following options you may way to leave as the default or override: Number of tails: alternative = “two.sided” Default Allows for a 2-sided alternative alternative = “less” Only Allows: group 1 &lt; group 2 alternative = “greater” Only Allows: group 1 &gt; group 2 Confidence level: conf.level = 0.95 Default Computes the 95% confidence inverval conf.level = 0.90 Changes to a 90% confidence interval 3.3.1 All Defaults Is there evidence the population mean weight is DIFFERENT than 165? cancer_clean %&gt;% dplyr::pull(weighin) %&gt;% # pull the continuous varaible out t.test(mu = 165) # specify the null hypothesis value One Sample t-test data: . t = 2.0765, df = 24, p-value = 0.04872 alternative hypothesis: true mean is not equal to 165 95 percent confidence interval: 165.0807 191.4793 sample estimates: mean of x 178.28 There is evidence that cancer patients weight more (N = 25, M = 178.28) now than the historic average of 165 pound, \\(t(24) = 2.077, p = .049, 95% CI: 165.08, 191.48\\). 3.3.2 Confidence Level other than 95% Find a 99% confience level for the population mean weight. cancer_clean %&gt;% dplyr::pull(weighin) %&gt;% # pull the continuous varaible out t.test(mu = 165, # specify the null hypothesis value conf.level = 0.99) # over-ride the default of 95% CI One Sample t-test data: . t = 2.0765, df = 24, p-value = 0.04872 alternative hypothesis: true mean is not equal to 165 99 percent confidence interval: 160.3927 196.1673 sample estimates: mean of x 178.28 There is evidence that cancer patients weight more (N = 25, M = 178.28) now than the historic average of 165 pound, \\(t(24) = 2.077, p = .049, 99% CI: 160.39, 196.17\\). 3.3.3 One-Sided Test, instead of Two Is there evidence the population mean weight is GREATER than 165? cancer_clean %&gt;% dplyr::pull(weighin) %&gt;% # pull the continuous varaible out t.test(mu = 165, # specify the null hypothesis value alternative = &quot;greater&quot;) # over-ride the default of 95% CI One Sample t-test data: . t = 2.0765, df = 24, p-value = 0.02436 alternative hypothesis: true mean is greater than 165 95 percent confidence interval: 167.3384 Inf sample estimates: mean of x 178.28 Notice than one end of the confidence interval is Inf for infinity. This always happens when you specify a one-tail test, so you should IGNORE the conficence interval reported when you specify alternative =. There is evidence that cancer patients weight more (N = 25, M = 178.28) now than the historic average of 165 pound, \\(t(24) = 2.077, p = .024\\). 3.3.4 Restrict to a Subsample Do the patients with stage 3 and 4 cancer weigh more than 165 pounds at intake, on average? cancer_clean %&gt;% dplyr::filter(stage %in% c(&quot;3&quot;, &quot;4&quot;)) %&gt;% # select a sub-sample dplyr::pull(weighin) %&gt;% # pull the continuous varaible out t.test(mu = 165) # specify the null hypothesis value One Sample t-test data: . t = 0.82627, df = 5, p-value = 0.4463 alternative hypothesis: true mean is not equal to 165 95 percent confidence interval: 137.0283 219.4717 sample estimates: mean of x 178.25 There is NO evidence that stage three and four cancer (n = 6, M = 178.25) patients weight more now than the historic average of 165 pound, \\(t(24) = 0.826, p = .446\\). 3.4 Inho example From Baron H. Cohen’s Explaining Psychological Statistics, page 196. To review, we can easily run a one-sample t-test with a few simple lines of code. data_ihno %&gt;% dplyr::pull(hr_base) %&gt;% t.test(mu = 72.5) One Sample t-test data: . t = -0.71525, df = 99, p-value = 0.4761 alternative hypothesis: true mean is not equal to 72.5 95 percent confidence interval: 71.63194 72.90806 sample estimates: mean of x 72.27 We can repeat this process to test any number of variables against a specified population parameter: data_ihno %&gt;% dplyr::pull(hr_pre) %&gt;% t.test(mu = 72.5) One Sample t-test data: . t = 2.6309, df = 99, p-value = 0.009878 alternative hypothesis: true mean is not equal to 72.5 95 percent confidence interval: 72.83183 74.86817 sample estimates: mean of x 73.85 data_ihno %&gt;% dplyr::pull(hr_post) %&gt;% t.test(mu = 72.5) One Sample t-test data: . t = 0.63295, df = 99, p-value = 0.5282 alternative hypothesis: true mean is not equal to 72.5 95 percent confidence interval: 71.85954 73.74046 sample estimates: mean of x 72.8 "],["two-independent-samples-t-test-for-the-difference-in-means.html", "4 TWO INDEPENDENT SAMPLES t-TEST: for the Difference in MEANS 4.1 Exploratory Data Analysis: i.e. the eyeball method 4.2 Assumptions 4.3 Inference", " 4 TWO INDEPENDENT SAMPLES t-TEST: for the Difference in MEANS Using the t.test() function library(car) # Companion for Applied Regression (and ANOVA) 4.1 Exploratory Data Analysis: i.e. the eyeball method Do the two groups, treatment and control, have different oral conditions at initial observation? What about four weeks later? Judge any difference in centers (means) within the context of the within group spread (stadard deviation/variance) 4.1.1 Means and SDs cancer_clean %&gt;% dplyr::group_by(trt) %&gt;% furniture::table1(totalcin, totalcw4, na.rm = FALSE) ──────────────────────────────── trt Placebo Aloe Juice n = 14 n = 11 totalcin 6.6 (0.9) 6.5 (2.1) totalcw4 10.1 (3.6) 10.6 (3.5) ──────────────────────────────── 4.1.2 Stacked Histograms 4.1.2.1 Baseline Oral Condition cancer_clean %&gt;% ggplot(aes(totalcin)) + geom_histogram(bins = 10) + facet_grid(trt ~ .) 4.1.2.2 Four Weeks Oral Condition cancer_clean %&gt;% ggplot(aes(totalcw4)) + geom_histogram(bins = 10) + facet_grid(trt ~ .) 4.1.3 Side-by-Side Boxplots 4.1.3.1 Baseline Oral Condition cancer_clean %&gt;% ggplot(aes(x = trt, y = totalcin)) + geom_boxplot() 4.1.3.2 Four Weeks Oral Condition cancer_clean %&gt;% ggplot(aes(x = trt, y = totalcw4)) + geom_boxplot() 4.2 Assumptions 4.2.1 Independence BOTH Samples were drawn INDEPENDENTLY at random (at least as representative as possible) Nothing can be done to fix NON-representative samples! Can not for with any statistically test If idenpendence is violated, you may want to use a paired-samples t-test 4.2.2 Normality A variable is said to follow the normal distribution if it resembles the normal curve. Specifically it is symetrical, unimodal, and bell shaped. The continuous variable has a NORMAL distribution in BOTH populations Not as important if the sample is large (Central Limit Theorem) IF the sample is far from normal &amp;/or small, might want to use a different method Options to judging normality: Visualization of each sample’s distribution Stacked histograms, but is sensitive to binning choices (number or width) Side-by-side boxplots, shows median instead of mean as central line Seperate QQ plots (straight \\(45^\\circ\\) line), but is sensitive to outliers! Calculate Skewness and Kurtosis, within each group Divided each value by its standard error (SE) A result \\(\\gt \\pm 2\\) indicates issues Formal Inferencial Tests for Normality, on each group Null-hypothesis: population is normally distributed A \\(p \\lt .05\\) ???indicate snon-normality For smaller samples, use Shapiro-Wilk’s Test For larger samples, use Kolmogorov-Smirnov’s Test 4.2.2.1 Baseline Oral Condition cancer_clean %&gt;% ggplot(aes(sample = totalcin)) + # make sure to include &quot;sample = &quot; geom_qq() + # layer on the dots stat_qq_line() + # layer on the line facet_grid(. ~ trt) # panel by group cancer_clean %&gt;% dplyr::filter(trt == &quot;Placebo&quot;) %&gt;% # select one group dplyr::pull(totalcin) %&gt;% # extract the continuous variable shapiro.test() # test for normality Shapiro-Wilk normality test data: . W = 0.6807, p-value = 0.0002349 cancer_clean %&gt;% dplyr::filter(trt == &quot;Aloe Juice&quot;) %&gt;% # select one group dplyr::pull(totalcin) %&gt;% # extract the continuous variable shapiro.test() # test for normality Shapiro-Wilk normality test data: . W = 0.78534, p-value = 0.006034 Shapiro-Wilk’s tests yield evidence that baseline oral condition is NOT normally distributed in the placebo group, W = .681, p &lt;.001, nor the treatment group, W = .785, p = .006. Visual inspection suggests that violatioins may by more extreme in the placebo group. 4.2.2.2 Four Weeks Oral Condition cancer_clean %&gt;% ggplot(aes(sample = totalcw4)) + # make sure to include &quot;sample = &quot; geom_qq() + # layer on the dots stat_qq_line() + # layer on the line facet_grid(. ~ trt) # panel by group cancer_clean %&gt;% dplyr::filter(trt == &quot;Placebo&quot;) %&gt;% # select one group dplyr::pull(totalcw4) %&gt;% # extract the continuous variable shapiro.test() # test for normality Shapiro-Wilk normality test data: . W = 0.88272, p-value = 0.06356 cancer_clean %&gt;% dplyr::filter(trt == &quot;Aloe Juice&quot;) %&gt;% # select one group dplyr::pull(totalcw4) %&gt;% # extract the continuous variable shapiro.test() # test for normality Shapiro-Wilk normality test data: . W = 0.92906, p-value = 0.4014 Shapiro-Wilk’s tests yielded no evidence that oral condition is NOT normally distributed four weeks after baseline in the placebo group, \\(W = .883, p = .064\\), and the treatment group, \\(W = .929, p = .401\\). 4.2.3 HOV Two Populations exhibit Homogeneity of Variance (HOV), i.e. have about the same amount of spread Before performing the \\(t\\) test, check to see if the assumption of homogeneity of variance is met using Levene’s Test. For a independent samples t-test for means, the groups need to have the same amount of spread (SD) in the measure of interest. Use the car:leveneTest() function tests the HOV assumtion. Inside the funtion you need to specify at least three options (sepearated by commas): the formula: continuous_var ~ grouping_var (replace with your variable names) the dataset: data = . to pipe it from above the center: center = “mean” since we are comparing means 4.2.3.1 Baseline Oral Condition Do the participants in the treatment and control groups have the same spread in oral condition at BASELINE? cancer_clean %&gt;% car::leveneTest(totalcin ~ trt, # formula: continuous_var ~ grouping_var data = ., # pipe in the dataset center = &quot;mean&quot;) # The default is &quot;median&quot; Levene&#39;s Test for Homogeneity of Variance (center = &quot;mean&quot;) Df F value Pr(&gt;F) group 1 2.2103 0.1507 23 No violations of homogeneity were detected, \\(F(1, 23) = 2.210, p = .151\\). 4.2.3.2 Four Weeks Oral Condition Do the participants in the treatment and control groups have the same spread in oral condition at the FOURTH WEEK? cancer_clean %&gt;% car::leveneTest(totalcw4 ~ trt, # formula: continuous_var ~ grouping_var data = ., # pipe in the dataset center = &quot;mean&quot;) # The default is &quot;median&quot; Levene&#39;s Test for Homogeneity of Variance (center = &quot;mean&quot;) Df F value Pr(&gt;F) group 1 0 0.995 23 No violations of homogeneity were detected, \\(F(1, 23) = 0, p = .995\\). 4.3 Inference Formal Statistical Test: t-Test for Difference in Independent Group Means Use the same t.test() funtion we have used for a single sample, but speficy a few more options. Inside the funtion you need to specify at least three options (sepearated by commas): the formula: continuous_var ~ grouping_var (replace with your variable names) the dataset: data = . to pipe it from above You MAY need/want to specify some or all of the following options you may way to leave as the default or override: HOV assumed: var.equal = FALSE Default Seperate-Variance test using Welch’s df var.equal = TRUE Pooled-Variance test (if HOV is NOT violated) Number of tails: alternative = “two.sided” Default Allows for a 2-sided alternative alternative = “less” Only Allows: group 1 &lt; group 2 alternative = “greater” Only Allows: group 1 &gt; group 2 Independent vs. paired: paired = FALSE Default Conducts an INDEOENDENT groups t-Test paired = TRUE Conducts a PAIRED meausres t-Test Confidence level: conf.level = 0.95 Default Computes the 95% confidence inverval conf.level = 0.90 Changes to a 90% confidence interval 4.3.1 Pooled Variance Test Use when there are no violations of HOV 4.3.1.1 Baseline Oral Condition Do the participants in the treatment group have a different average oral condition at BASELINE, compared to the control group? # Minimal syntax cancer_clean %&gt;% t.test(totalcin ~ trt, # formula: continuous_var ~ grouping_var data = ., # pipe in the dataset var.equal = TRUE) # HOV was violated (option = TRUE) Two Sample t-test data: totalcin by trt t = 0.18566, df = 23, p-value = 0.8543 alternative hypothesis: true difference in means between group Placebo and group Aloe Juice is not equal to 0 95 percent confidence interval: -1.185479 1.419245 sample estimates: mean in group Placebo mean in group Aloe Juice 6.571429 6.454545 No evidence of a differnece in mean oral condition at baseline, \\(t(23) = 0.186, p = .854\\). Note: this test may be unreliable due to the non-normality of the samll samples. 4.3.1.2 Four Weeks Oral Condition Do the participants in the treatment group have a different average oral condition at the FOURTH WEEK, compared to the control group? # Fully specified function cancer_clean %&gt;% t.test(totalcw4 ~ trt, # formula: continuous_var ~ grouping_var data = ., # pipe in the dataset var.equal = TRUE, # default: HOV was violated (option = TRUE) alternative = &quot;two.sided&quot;, # default: 2 sided (options = &quot;less&quot;, &quot;greater&quot;) paired = FALSE, # default: independent (option = TRUE) conf.level = .95) # default: 95% (option = .9, .90, ect.) Two Sample t-test data: totalcw4 by trt t = -0.34598, df = 23, p-value = 0.7325 alternative hypothesis: true difference in means between group Placebo and group Aloe Juice is not equal to 0 95 percent confidence interval: -3.444215 2.457202 sample estimates: mean in group Placebo mean in group Aloe Juice 10.14286 10.63636 No evidence of a differnece in mean oral condition at the fourth week, \\(t(23) = -0.350, p = .733\\). 4.3.2 Seperate Variance Test Use if there are violations of HOV or the samples are difference sizes "],["one-way-anova-code.html", "5 One-Way ANOVA: Code 5.1 Prepare for Modeling 5.2 Fitting One-way ANOVA Model 5.3 Followup-tests", " 5 One-Way ANOVA: Code Required Packages library(tidyverse) # Loads several very helpful &#39;tidy&#39; packages library(furniture) # Nice tables (by our own Tyson Barrett) library(afex) # Analysis of Factorial Experiments library(emmeans) # Estimated marginal means (Least-squares means) library(readxl) # Necessary for reading in an example data set 5.1 Prepare for Modeling 5.1.1 Ensure the Data is in “long” Format First, the data must be restructured from wide to long format, so that each observation is on its own line. All categorical variables must be declared as factors. We also must add an distinct indicator variable. Name of the dataset: data_long Variables: id_var Name of the variable that is qunique for each unit of study (i.e. person) group_IV Name of the categorical variable (factor) with at least 2 levels continuous_DV Name of the continuous varaible (dbl) that we want to compare the averages of 5.1.2 Compute Summary Statistics Second, check the summary statistics for each of the \\(k\\) groups. # Raw data: summary table data_long %&gt;% dplyr::group_by(group_IV) %&gt;% # divide into groups furniture::table1(continuous_DV # gives M(SD) digits = 2, na.rm = FALSE, total = TRUE, output = &quot;markdown&quot;) 5.1.3 Plot the Raw Data Third, plot the data to eyeball the potential effect. Remember the center line in each box represents the median, not the mean. # Raw data: boxplots data_long %&gt;% ggplot(aes(x = group_IV, y = continuous_DV)) + geom_boxplot() + geom_point() # Raw data: Mean-SD plots data_long %&gt;% ggplot(aes(x = group_IV, y = continuous_DV)) + stat_summary() 5.1.4 Assumption Check: HOV It is important that we test for violations of the assumption of Homogeneity of variance. # Levene&#39;s Test of HOV data_name %&gt;% car::leveneTest(continuous_var ~ group_var, data = ., center = &quot;mean&quot;) 5.2 Fitting One-way ANOVA Model The aov_4() function from the afex package fits ANOVA models (oneway, two-way, repeated measures, and mixed design). It needs at least two arguments: formula: continuous_DV ~ group_IV + (1|id_var) one observation per subject and id_var is distinct for each subject dataset: data = . we use the period to signify that the datset is being piped from above Here is an outline of what your syntax should look like when you fit and save a one-way ANOVA. Of course you will replace the dataset name and the variable names, as well as the name you are saving it as. NOTE: The aov_4() function works on data in LONG format only. Each observation needs to be on its one line or row with seperate variables for the group membership (categorical factor or fct) and the continuous measurement (numberic or dbl). # One-way ANOVA: fit and save aov_name &lt;- data_long %&gt;% afex::aov_4(continuous_DV ~ group_IV + (1|id_var), data = .) 5.2.1 Basic Output - stored name of model By running the name you saved you model under, you will get a brief set of output, including a measure of Effect Size. NOTE: The ges is the generalized eta squared. In a one-way ANOVA, the eta-squared effect size is only one value, ie. generalized \\(\\eta_g\\) and partial \\(\\eta_p\\) are the same. # Display basic ANOVA results (includes effect size) aov_name 5.2.2 Fuller Output - add $Anova on model name To fully fill out a standard ANOVA table and compute other effect sizes, you will need a more complete set of output, including the Sum of Squares components, you will need to add $Anova at the end of the model name before running it. NOTE: IGNORE the first line that starts with (Intercept)! Also, the ‘mean sum of squares’ are not included in this table, nor is the Total line at the bottom of the standard ANOVA table. You will need to manually compute these values and add them on the homework page. Remember that Sum of Squares (SS) and degrees of freedom (df) add up, but Mean Sum of Squreas (MS) do not add up. Also: MS = SS/df for each term. # Display fuller ANOVA results (includes sum of squares) aov_name$Anova 5.3 Followup-tests 5.3.1 Estimated Marginal Means with emmeans::emmeans(~ group_var) aov_name %&gt;% emmeans::emmeans(~ group_var) # Calculate Estimated Marinal Means 5.3.2 All Pairwise Comparisons with pairs() There are two steps to conduct all possible pairwise comparisons: emmeans::emmeans(~ group_var) - Calculate the Estimated Marinal Means pairs() - Determine if each pair is significantly different Within the pairs() function there are several options for controling for multiple comparisons, including: adjust = \"none\" - Fisher’s LSD adjust = \"tukey\" - Tukey’s HSD adjust = \"bon\" - Bonferroni # Pairwise post hoc: Tukey&#39;s HSD adjustment for multiple comparisons aov_name %&gt;% emmeans::emmeans(~ group_var) %&gt;% # Calculate Estimated Marginal Means pairs(adjust = &quot;tukey&quot;) # Is each pair signif different? 5.3.3 Plot Marginal Means with emmeans::emmip(~ group_var) aov_name %&gt;% emmeans::emmip(~ group_var, # Calculate Estimated Marginal Means CIs = TRUE) # Include Confidence Intervals 5.3.4 Contrast Statements with emmeans::contrast() There are two steps to conduct a contrast comparison: emmeans(~ group_var) - Calculate the Estimated Marinal Means contrast() - Determine if each pair is significantly different Inside the contrast statement, list the named sets of linear contrast weights. We will only be doing one-at-a-time, but we must still use a nested list. NOTE: You must provide one weight (\\(c_i\\)) for each of the \\(k\\) groups. If you wish to ignore a group, that group’s weight is \\(c_i = 0\\). The sum total of all the weights must be zero (\\(\\sum c_i = 0\\)), so use positive and negative numbers. # Contrast statement : Impossible vs. Rest aov_name %&gt;% emmeans::emmeans(~ group_var) %&gt;% emmeans::contrast(list(&quot;your contrast name&quot; = c(c_1, c_2, ... , c_k))) "],["poison-example-1-2-way-anova.html", "6 Poison Example: 1 &amp; 2-way ANOVA 6.1 Prepare for Modeling 6.2 Example 1) Survival Time by Poison Type 6.3 Example 2) Survival Time by Treatment Type 6.4 Example 3) Survival Time by Both Poisson &amp; Treatment Type", " 6 Poison Example: 1 &amp; 2-way ANOVA Required Packages library(tidyverse) # Loads several very helpful &#39;tidy&#39; packages library(furniture) # Nice tables (by our own Tyson Barrett) library(afex) # Analysis of Factorial Experiments library(emmeans) # Estimated marginal means (Least-squares means) library(readxl) # Necessary for reading in an example data set 6.1 Prepare for Modeling 6.1.1 Ensure the Data is in “long” Format https://www.guru99.com/r-anova-tutorial.html The “poison” dataset contains 48 rows and 4 variables: ID: Guinea pig identification number Time: Survival time of the animal poison: Type of poison used: factor level: 1,2 and 3 treat: Type of treatment used: factor level: 1,2 and 3 Before you start to compute the ANOVA test, you need to prepare the data as follow: Import the data from online Rename the “id” variable Declare factors: poison type &amp; treatment PATH &lt;- &quot;https://raw.githubusercontent.com/guru99-edu/R-Programming/master/poisons.csv&quot; df_survival &lt;- read.csv(PATH) %&gt;% dplyr::rename(id = X) %&gt;% dplyr::mutate(poison = factor(poison)) %&gt;% dplyr::mutate(treat = factor(treat)) tibble::glimpse(df_survival) Rows: 48 Columns: 4 $ id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, … $ time &lt;dbl&gt; 0.31, 0.45, 0.46, 0.43, 0.36, 0.29, 0.40, 0.23, 0.22, 0.21, 0.1… $ poison &lt;fct&gt; 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 1, 1, 1, 1, 2, 2, 2, 2, 3, … $ treat &lt;fct&gt; A, A, A, A, A, A, A, A, A, A, A, A, B, B, B, B, B, B, B, B, B, … str(df_survival) &#39;data.frame&#39;: 48 obs. of 4 variables: $ id : int 1 2 3 4 5 6 7 8 9 10 ... $ time : num 0.31 0.45 0.46 0.43 0.36 0.29 0.4 0.23 0.22 0.21 ... $ poison: Factor w/ 3 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;: 1 1 1 1 2 2 2 2 3 3 ... $ treat : Factor w/ 4 levels &quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;: 1 1 1 1 1 1 1 1 1 1 ... 6.2 Example 1) Survival Time by Poison Type 6.2.1 Parepare for Analysis Our objective is to test the following assumption: H_0: There is no difference in survival time average between group H_a: The survival time average is different for at least one group. In other words, you want to know if there is a statistical difference between the mean of the survival time according to the type of poison given to the Guinea pig. Variables: id (id_var) Name of the variable that is qunique for each unit of study (i.e. person) poison (group_IV) Name of the categorical variable (factor) with at least 2 levels time (continuous_DV) Name of the continuous varaible (dbl) that we want to compare the averages of Note: ignore treat for now 6.2.1.1 Compute Summary Statistics Second, check the summary statistics for each of the \\(k\\) groups. # Raw data: summary table df_survival %&gt;% dplyr::group_by(poison) %&gt;% # divide into groups furniture::table1(&quot;Survival Time&quot; = time, digits = 2, # gives M(SD) na.rm = FALSE, total = TRUE, output = &quot;markdown&quot;, caption = &quot;Summary of Survival Time by Type of Poisson Used&quot;) Table 6.1: Summary of Survival Time by Type of Poisson Used Total 1 2 3 n = 48 n = 16 n = 16 n = 16 Survival Time 0.48 (0.25) 0.62 (0.21) 0.54 (0.29) 0.28 (0.06) 6.2.1.2 Plot the Raw Data Third, plot the data to eyeball the potential effect. Remember the center line in each box represents the median, not the mean. I have added a red diamond on the mean survival time for each type of poison. df_survival %&gt;% ggplot(aes(x = poison, y = time)) + geom_violin(fill = &quot;gray&quot;) + geom_boxplot(width = .07, fill = &quot;white&quot;) + geom_jitter(position = position_jitter(0.21)) + stat_summary(fun = mean, geom = &quot;point&quot;, shape = 18, color = &quot;red&quot;, size = 5) + theme_bw() + labs(x = &quot;Type of Treatment&quot;, y = &quot;Observed Survival Time&quot;) 6.2.1.3 Assumption Check: Normality df_survival %&gt;% ggplot(aes(time)) + geom_density(fill = &quot;gray&quot;, alpha = .5) + facet_grid(poison ~ ., labeller = label_both) + theme_bw() + labs(x = &quot;Observed Survival Time&quot;) 6.2.1.4 Assumption Check: HOV Levene’s Test of HOV df_survival %&gt;% car::leveneTest(time ~ poison, data = ., center = &quot;mean&quot;) Levene&#39;s Test for Homogeneity of Variance (center = &quot;mean&quot;) Df F value Pr(&gt;F) group 2 8.0941 0.0009937 *** 45 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 6.2.2 Fitting One-way ANOVA Model aov_poison &lt;- df_survival %&gt;% afex::aov_4(time ~ poison + (1|id), data = .) 6.2.2.1 Basic Output - stored name of model aov_poison Anova Table (Type 3 tests) Response: time Effect df MSE F ges p.value 1 poison 2, 45 0.04 11.79 *** .344 &lt;.001 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;+&#39; 0.1 &#39; &#39; 1 6.2.2.2 Fuller Output - add $Anova on model name aov_poison$Anova Anova Table (Type III tests) Response: dv Sum Sq Df F value Pr(&gt;F) (Intercept) 11.0304 1 251.700 &lt; 2.2e-16 *** poison 1.0330 2 11.786 7.656e-05 *** Residuals 1.9721 45 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 6.2.3 Followup-tests 6.2.3.1 Estimated Marginal Means with emmeans::emmeans() aov_poison %&gt;% emmeans::emmeans(~ poison) # Calculate Estimated Marginal Means poison emmean SE df lower.CL upper.CL 1 0.618 0.0523 45 0.512 0.723 2 0.544 0.0523 45 0.439 0.650 3 0.276 0.0523 45 0.171 0.382 Confidence level used: 0.95 aov_poison %&gt;% emmeans::emmip(~ poison, CIs = TRUE) + theme_bw() + labs(x = &quot;Type of Poison&quot;, y = &quot;Estmated Marginal Mean: Survival Time&quot;) 6.2.3.2 All Pairwise Comparisons with pairs() Pairwise post hoc: Fisher’s LSD adjustment for multiple comparisons aov_poison %&gt;% emmeans::emmeans(~ poison) %&gt;% # Calculate Estimated Marginal Means pairs(adjust = &quot;none&quot;) # Is each pair signif different? contrast estimate SE df t.ratio p.value poison1 - poison2 0.0731 0.074 45 0.988 0.3284 poison1 - poison3 0.3412 0.074 45 4.611 &lt;.0001 poison2 - poison3 0.2681 0.074 45 3.623 0.0007 6.2.3.3 Contrast Statements with emmeans::contrast() aov_poison %&gt;% emmeans::emmeans(~ poison) %&gt;% emmeans::contrast(list(&quot;1 &amp; 2 vs. 3&quot; = c(1, 1, -2))) contrast estimate SE df t.ratio p.value 1 &amp; 2 vs. 3 0.609 0.128 45 4.754 &lt;.0001 6.3 Example 2) Survival Time by Treatment Type 6.3.1 Parepare for Analysis Our objective is to test the following assumption: H_0: There is no difference in survival time average between group H_a: The survival time average is different for at least one group. In other words, you want to know if there is a statistical difference between the mean of the survival time according to the type of treatment given to the Guinea pig. Variables: id (id_var) Name of the variable that is qunique for each unit of study (i.e. person) treat (group_IV) Name of the categorical variable (factor) with at least 2 levels time (continuous_DV) Name of the continuous varaible (dbl) that we want to compare the averages of Note: ignore poison for now 6.3.1.1 Compute Summary Statistics Second, check the summary statistics for each of the \\(k\\) groups. # Raw data: summary table df_survival %&gt;% dplyr::group_by(treat) %&gt;% # divide into groups furniture::table1(&quot;Survival Time&quot; = time, digits = 2, # gives M(SD) na.rm = FALSE, total = TRUE, output = &quot;markdown&quot;, caption = &quot;Summary of Survival Time by Type of Treatment Used&quot;) Table 6.2: Summary of Survival Time by Type of Treatment Used Total A B C D n = 48 n = 12 n = 12 n = 12 n = 12 Survival Time 0.48 (0.25) 0.31 (0.10) 0.68 (0.32) 0.39 (0.17) 0.53 (0.22) 6.3.1.2 Plot the Raw Data Third, plot the data to eyeball the potential effect. Remember the center line in each box represents the median, not the mean. I have added a red diamond on the mean survival time for each type of poison. df_survival %&gt;% ggplot(aes(x = treat, y = time)) + geom_violin(fill = &quot;gray&quot;) + geom_boxplot(width = .07, fill = &quot;white&quot;) + geom_jitter(position = position_jitter(0.21)) + stat_summary(fun = mean, geom = &quot;point&quot;, shape = 18, color = &quot;red&quot;, size = 5) + theme_bw() + labs(x = &quot;Type of Treatment&quot;, y = &quot;Observed Survival Time&quot;) 6.3.1.3 Assumption Check: Normality df_survival %&gt;% ggplot(aes(time)) + geom_density(fill = &quot;gray&quot;, alpha = .5) + facet_grid(treat ~ ., labeller = label_both) + theme_bw() + labs(x = &quot;Observed Survival Time&quot;) 6.3.1.4 Assumption Check: HOV Levene’s Test of HOV df_survival %&gt;% car::leveneTest(time ~ treat, data = ., center = &quot;mean&quot;) Levene&#39;s Test for Homogeneity of Variance (center = &quot;mean&quot;) Df F value Pr(&gt;F) group 3 6.0747 0.001494 ** 44 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 6.3.2 Fitting One-way ANOVA Model aov_treat &lt;- df_survival %&gt;% afex::aov_4(time ~ treat + (1|id), data = .) 6.3.2.1 Basic Output - stored name of model aov_treat Anova Table (Type 3 tests) Response: time Effect df MSE F ges p.value 1 treat 3, 44 0.05 6.48 *** .307 &lt;.001 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;+&#39; 0.1 &#39; &#39; 1 6.3.2.2 Fuller Output - add $Anova on model name aov_treat$Anova Anova Table (Type III tests) Response: dv Sum Sq Df F value Pr(&gt;F) (Intercept) 11.0304 1 232.9019 &lt; 2.2e-16 *** treat 0.9212 3 6.4836 0.0009921 *** Residuals 2.0839 44 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 6.3.3 Followup-tests 6.3.3.1 Estimated Marginal Means with emmeans::emmeans() aov_treat %&gt;% emmeans::emmeans(~ treat) # Calculate Estimated Marginal Means treat emmean SE df lower.CL upper.CL A 0.314 0.0628 44 0.188 0.441 B 0.677 0.0628 44 0.550 0.803 C 0.393 0.0628 44 0.266 0.519 D 0.534 0.0628 44 0.408 0.661 Confidence level used: 0.95 aov_treat %&gt;% emmeans::emmip(~ treat, CIs = TRUE) + theme_bw() + labs(x = &quot;Type of Treatment&quot;, y = &quot;Estmated Marginal Mean: Survival Time&quot;) 6.3.3.2 All Pairwise Comparisons with pairs() Pairwise post hoc: Fisher’s LSD adjustment for multiple comparisons aov_treat %&gt;% emmeans::emmeans(~ treat) %&gt;% # Calculate Estimated Marginal Means pairs(adjust = &quot;none&quot;) # Is each pair signif different? contrast estimate SE df t.ratio p.value A - B -0.3625 0.0888 44 -4.080 0.0002 A - C -0.0783 0.0888 44 -0.882 0.3827 A - D -0.2200 0.0888 44 -2.476 0.0172 B - C 0.2842 0.0888 44 3.198 0.0026 B - D 0.1425 0.0888 44 1.604 0.1159 C - D -0.1417 0.0888 44 -1.595 0.1180 6.3.3.3 Contrast Statements with emmeans::contrast() aov_treat %&gt;% emmeans::emmeans(~ treat) %&gt;% emmeans::contrast(list(&quot;B vs. Rest&quot; = c(1, -3, 1, 1))) contrast estimate SE df t.ratio p.value B vs. Rest -0.789 0.218 44 -3.626 0.0007 6.4 Example 3) Survival Time by Both Poisson &amp; Treatment Type 6.4.1 Parepare for Analysis Our objective is to test the following assumption: H_0: There is no difference in survival time average between group H_a: The survival time average is different for at least one group. In other words, you want to know if there is a statistical difference between the mean of the survival time according to the type of treatment given to the Guinea pig. Variables: id (id_var) Name of the variable that is qunique for each unit of study (i.e. person) treat &amp; poison (group_IV) Name of the categorical variable (factor) with at least 2 levels time (continuous_DV) Name of the continuous varaible (dbl) that we want to compare the averages of Note: ignore poison for now 6.4.1.1 Compute Summary Statistics Second, check the summary statistics for each of the \\(k\\) groups. df_survival %&gt;% dplyr::group_by(treat, poison) %&gt;% # divide into groups dplyr::summarise(n = n(), mean = mean(time), sd = sd(time)) %&gt;% gt::gt(caption = &quot;Summary of Survival Time by Type of Treatment Used&quot;) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #dsfhdfgxpm .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #dsfhdfgxpm .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #dsfhdfgxpm .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #dsfhdfgxpm .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #dsfhdfgxpm .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dsfhdfgxpm .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #dsfhdfgxpm .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #dsfhdfgxpm .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #dsfhdfgxpm .gt_column_spanner_outer:first-child { padding-left: 0; } #dsfhdfgxpm .gt_column_spanner_outer:last-child { padding-right: 0; } #dsfhdfgxpm .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #dsfhdfgxpm .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #dsfhdfgxpm .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #dsfhdfgxpm .gt_from_md > :first-child { margin-top: 0; } #dsfhdfgxpm .gt_from_md > :last-child { margin-bottom: 0; } #dsfhdfgxpm .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #dsfhdfgxpm .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #dsfhdfgxpm .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #dsfhdfgxpm .gt_row_group_first td { border-top-width: 2px; } #dsfhdfgxpm .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #dsfhdfgxpm .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #dsfhdfgxpm .gt_first_summary_row.thick { border-top-width: 2px; } #dsfhdfgxpm .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dsfhdfgxpm .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #dsfhdfgxpm .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #dsfhdfgxpm .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #dsfhdfgxpm .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #dsfhdfgxpm .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #dsfhdfgxpm .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #dsfhdfgxpm .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #dsfhdfgxpm .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #dsfhdfgxpm .gt_left { text-align: left; } #dsfhdfgxpm .gt_center { text-align: center; } #dsfhdfgxpm .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #dsfhdfgxpm .gt_font_normal { font-weight: normal; } #dsfhdfgxpm .gt_font_bold { font-weight: bold; } #dsfhdfgxpm .gt_font_italic { font-style: italic; } #dsfhdfgxpm .gt_super { font-size: 65%; } #dsfhdfgxpm .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #dsfhdfgxpm .gt_asterisk { font-size: 100%; vertical-align: 0; } #dsfhdfgxpm .gt_indent_1 { text-indent: 5px; } #dsfhdfgxpm .gt_indent_2 { text-indent: 10px; } #dsfhdfgxpm .gt_indent_3 { text-indent: 15px; } #dsfhdfgxpm .gt_indent_4 { text-indent: 20px; } #dsfhdfgxpm .gt_indent_5 { text-indent: 25px; } Table 6.3: Summary of Survival Time by Type of Treatment Used poison n mean sd A 1 4 0.4125 0.06946222 2 4 0.3200 0.07527727 3 4 0.2100 0.02160247 B 1 4 0.8800 0.16083117 2 4 0.8150 0.33630343 3 4 0.3350 0.04654747 C 1 4 0.5675 0.15671099 2 4 0.3750 0.05686241 3 4 0.2350 0.01290994 D 1 4 0.6100 0.11284207 2 4 0.6675 0.27097048 3 4 0.3250 0.02645751 6.4.1.2 Plot the Raw Data Third, plot the data to eyeball the potential effect. Remember the center line in each box represents the median, not the mean. I have added a red diamond on the mean survival time for each type of poison. df_survival %&gt;% ggplot(aes(x = treat, y = time)) + geom_violin(fill = &quot;gray&quot;) + geom_boxplot(width = .07, fill = &quot;white&quot;) + geom_jitter(position = position_jitter(0.21)) + stat_summary(fun = mean, geom = &quot;point&quot;, shape = 18, color = &quot;red&quot;, size = 5) + theme_bw() + labs(x = &quot;Type of Treatment&quot;, y = &quot;Observed Survival Time&quot;) + facet_wrap(~ poison, labeller = label_both) 6.4.1.3 Assumption Check: Normality df_survival %&gt;% ggplot(aes(time)) + geom_density(fill = &quot;gray&quot;, alpha = .5) + facet_grid(treat ~ poison, labeller = label_both) + theme_bw() + labs(x = &quot;Observed Survival Time&quot;) 6.4.1.4 Assumption Check: HOV Levene’s Test of HOV df_survival %&gt;% car::leveneTest(time ~ treat*poison, data = ., center = &quot;mean&quot;) Levene&#39;s Test for Homogeneity of Variance (center = &quot;mean&quot;) Df F value Pr(&gt;F) group 11 4.8535 0.0001442 *** 36 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 6.4.2 Fitting Two-way ANOVA Model aov_survival2 &lt;- df_survival %&gt;% afex::aov_4(time ~ poison*treat + (1|id), data = .) 6.4.2.1 Basic Output - stored name of model aov_survival2 Anova Table (Type 3 tests) Response: time Effect df MSE F ges p.value 1 poison 2, 36 0.02 23.22 *** .563 &lt;.001 2 treat 3, 36 0.02 13.81 *** .535 &lt;.001 3 poison:treat 6, 36 0.02 1.87 .238 .112 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;+&#39; 0.1 &#39; &#39; 1 6.4.2.2 Fuller Output - add $Anova on model name aov_survival2$Anova Anova Table (Type III tests) Response: dv Sum Sq Df F value Pr(&gt;F) (Intercept) 11.0304 1 495.9194 &lt; 2.2e-16 *** poison 1.0330 2 23.2217 3.331e-07 *** treat 0.9212 3 13.8056 3.777e-06 *** poison:treat 0.2501 6 1.8743 0.1123 Residuals 0.8007 36 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 6.4.3 Followup-tests 6.4.3.1 Estimated Marginal Means with emmeans::emmeans() 6.4.3.2 All Pairwise Comparisons for Main Effects of Poison aov_survival2 %&gt;% emmeans::emmeans(~ poison) %&gt;% # Calculate Estimated Marginal Means pairs(adjust = &quot;none&quot;) # Is each pair signif different? contrast estimate SE df t.ratio p.value poison1 - poison2 0.0731 0.0527 36 1.387 0.1740 poison1 - poison3 0.3412 0.0527 36 6.472 &lt;.0001 poison2 - poison3 0.2681 0.0527 36 5.085 &lt;.0001 Results are averaged over the levels of: treat aov_survival2 %&gt;% emmeans::emmip( ~ poison, CIs = TRUE) + theme_bw() + labs(x = &quot;Type of Poison&quot;, y = &quot;Estmated Marginal Mean: Survival Time&quot;) 6.4.3.3 All Pairwise Comparisons for Main Effects of Treatment aov_survival2 %&gt;% emmeans::emmeans(~ treat) %&gt;% # Calculate Estimated Marginal Means pairs(adjust = &quot;tukey&quot;) # Is each pair signif different? contrast estimate SE df t.ratio p.value A - B -0.3625 0.0609 36 -5.954 &lt;.0001 A - C -0.0783 0.0609 36 -1.287 0.5772 A - D -0.2200 0.0609 36 -3.613 0.0049 B - C 0.2842 0.0609 36 4.667 0.0002 B - D 0.1425 0.0609 36 2.340 0.1077 C - D -0.1417 0.0609 36 -2.327 0.1108 Results are averaged over the levels of: poison P value adjustment: tukey method for comparing a family of 4 estimates aov_survival2 %&gt;% emmeans::emmip( ~ treat, CIs = TRUE) + theme_bw() + labs(x = &quot;Type of Treatment&quot;, y = &quot;Estmated Marginal Mean: Survival Time&quot;) "],["repeated-measures-anova.html", "7 Repeated Measures ANOVA 7.1 Tutorial - Fitting RM ANOVA Models with afex::aov_4() 7.2 Words Recalled Data Example (Chapter 15, section A) 7.3 Another Example - Weight Loss", " 7 Repeated Measures ANOVA Required Packages library(tidyverse) # Loads several very helpful &#39;tidy&#39; packages library(furniture) # Nice tables (by our own Tyson Barrett) library(afex) # needed for ANOVA, emmeans is loaded automatically. library(multcomp) # for advanced control for multiple testing/Type 1 error 7.1 Tutorial - Fitting RM ANOVA Models with afex::aov_4() The aov_4() function from the afex package fits ANOVA models (oneway, two-way, repeated measures, and mixed design). It needs at least two arguments: formula: continuous_var ~ 1 + (RM_var|id_var) one observation per subject for each level of the RMvar, so each id_var has multiple lines for each subject dataset: data = . we use the period to signify that the datset is being piped from above Here is an outline of what your syntax should look like when you fit and save a RM ANOVA. Of course you will replace the dataset name and the variable names, as well as the name you are saving it as. NOTE: The aov_4() function works on data in LONG format only. Each observation needs to be on its one line or row with seperate variables for the group membership (categorical factor or fct) and the continuous measurement (numberic or dbl). # RM ANOVA: fit and save aov_name &lt;- data_name %&gt;% afex::aov_4(continuous_var ~ 1 + (RM_var|id_var), data = .) By running the name you saved you model under, you will get a brief set of output, including a measure of Effect Size. NOTE: The ges is the generalized eta squared. In a one-way ANOVA, the eta-squared effect size is the same value, ie. generalized \\(\\eta_g\\) and partial \\(\\eta_p\\) are the same. # Display basic ANOVA results (includes effect size) aov_name To fully fill out a standard ANOVA table and compute other effect sizes, you will need a more complete set of output, including the Sum of Squares components, you will need to add summary() piped at the end of the model name before running it or after the model with a pipe. NOTE: IGNORE the first line that starts with (Intercept)! Also, the ‘mean sum of squares’ are not included in this table, nor is the Total line at the bottom of the standard ANOVA table. You will need to manually compute these values and add them on the homework page. Remember that Sum of Squares (SS) and degrees of freedom (df) add up, but Mean Sum of Squreas (MS) do not add up. Also: MS = SS/df for each term. This also runs and displays the results of Mauchly Tests for Sphericity, as well as the Greenhouse-Geisser (GG) and Huynh-Feldt (HF) Corrections to the p-value. If the Mauchly’s p-value is bigger than .05, do not use the corrections. If Mauchly’s p-value is less than .05, then apply the epsilon (eps or \\(\\epsilon\\)) to multiply the degree’s of freedom. Yes, the df will be decimal numbers. # Display fuller ANOVA results (sphericity tests) summary(aov_name) To see all the Sumes-of-Squared residuals for ALL of the model comoponents, you add $aov at the end of the model name. # Display all the sum of squares aov_name$aov Repeated Measures MANOVA Tests (Pillai test statistic) is computed is you add $Anova at the end of the model name. This is a so called ‘Multivariate Test’. This is NOT what you want to do! # Display fuller ANOVA results (includes sum of squares) aov_name$Anova If you only need to obtain the omnibus (overall) F-test without a correction for violation of sphericity, you can add an option for correction = \"none\". You can also request both the generalized and partial \\(\\eta^2\\) effect sizes with es = c(\"ges\", \"pes\"). # RM ANOVA: no correction, both effect sizes data_name %&gt;% afex::aov_4(continuous_var ~ 1 + (RM_var|id_var), data = ., anova_table = list(correction = &quot;none&quot;, es = c(&quot;ges&quot;, &quot;pes&quot;))) Post Hoc tests may be ran the same way as the 1 and 2-way ANOVAs from the last unit. NOTE: Use Fisher’s LSD (adjust = “none”) if the omnibus F-test is significant AND there are THREE measurements per subject or block. Tukey’s HSD (adjust = “tukey”) may be used even if the F-test is not significant or if there are four or more repeated measures. # RM ANOVA: post hoc all pairwise tests with Fisher&#39;s LSD correction aov_name %&gt;% emmeans::emmeans(~ RM_var) %&gt;% pairs(adjust = &quot;none&quot;) # RM ANOVA: post hoc all pairwise tests with Tukey&#39;s HSD correction aov_name %&gt;% emmeans::emmeans(~ RM_var) %&gt;% pairs(adjust = &quot;tukey&quot;) A means plot (model based) can help you write up your results. This zooms in on just the means and will make all differences seem significant, so make sure to interpret it in conjunction with the ANOVA and post hoc tests. # RM ANOVA: means plot aov_name %&gt;% emmeans::emmip(~ RM_var) 7.2 Words Recalled Data Example (Chapter 15, section A) 7.2.1 Data Prep I input the data as a tribble which saves it as a data.frame and then cleaned up a few of the important variables. d &lt;- tibble::tribble( ~ID, ~word_type, ~words_recalled, 1, 1, 20, 2, 1, 16, 3, 1, 8, 4, 1, 17, 5, 1, 15, 6, 1, 10, 1, 2, 21, 2, 2, 18, 3, 2, 7, 4, 2, 15, 5, 2, 10, 6, 2, 4, 1, 3, 17, 2, 3, 11, 3, 3, 4, 4, 3, 18, 5, 3, 13, 6, 3, 10) %&gt;% mutate(word_type = factor(word_type, labels = c(&quot;Neutral&quot;, &quot;Positive&quot;, &quot;Negative&quot;))) %&gt;% mutate(fake_id = row_number()) d # A tibble: 18 × 4 ID word_type words_recalled fake_id &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; 1 1 Neutral 20 1 2 2 Neutral 16 2 3 3 Neutral 8 3 4 4 Neutral 17 4 5 5 Neutral 15 5 6 6 Neutral 10 6 7 1 Positive 21 7 8 2 Positive 18 8 9 3 Positive 7 9 10 4 Positive 15 10 11 5 Positive 10 11 12 6 Positive 4 12 13 1 Negative 17 13 14 2 Negative 11 14 15 3 Negative 4 15 16 4 Negative 18 16 17 5 Negative 13 17 18 6 Negative 10 18 7.2.2 One-Way Independent ANOVA First, let’s ignore the fact that we know this has repeated measures. As such, we will assume that each word type group is independent. Let’s look at what happens: ind_anova &lt;- d %&gt;% afex::aov_4(words_recalled ~ word_type + (1|fake_id), data = .) ind_anova$Anova Anova Table (Type III tests) Response: dv Sum Sq Df F value Pr(&gt;F) (Intercept) 3042.00 1 101.4752 4.538e-08 *** word_type 16.33 2 0.2724 0.7652 Residuals 449.67 15 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 If we ignored that the word_type groups are not independent, we get an F-statistic = 0.272 and p = 0.765. What do you think will happen if we account for the repeated measures? Will the F-statistic increase or decrease? 7.2.3 One-Way RM ANOVA Now, let’s look at the repeated measures. We do this by using afex::aov_4() and then the summary() functions as shown below. oneway &lt;- d %&gt;% afex::aov_4(words_recalled ~ 1 + (word_type|ID), data = .) summary(oneway) Univariate Type III Repeated-Measures ANOVA Assuming Sphericity Sum Sq num Df Error SS den Df F value Pr(&gt;F) (Intercept) 3042.00 1 381.33 5 39.8864 0.001466 ** word_type 16.33 2 68.33 10 1.1951 0.342453 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Mauchly Tests for Sphericity Test statistic p-value word_type 0.2134 0.045538 Greenhouse-Geisser and Huynh-Feldt Corrections for Departure from Sphericity GG eps Pr(&gt;F[GG]) word_type 0.55972 0.3282 HF eps Pr(&gt;F[HF]) word_type 0.6077293 0.3309148 Here, we see a number of pieces of information, including the sums of squares, F-statistic, and p-value. The F-statistic is now 1.195 and the p-value (although still not signfiicant) is .342. So what happened to the F-statistic? It decreased! So by using the information that these are repeated measures, we have more power. Why is that? If we look at the output for the two ANOVAs above, both have the sums of squares for word_type at 16.33 so that didn’t change at all. So what did change? Well, it comes down to understanding what is happening to the error term. Although not shown explicitly in the tables above, consider that: \\[ \\text{Independent ANOVA: } SS_{total} = SS_{bet} + SS_w \\] \\[ \\text{RM ANOVA: } SS_{total} = SS_{RM} + SS_{sub} + SS_{inter} \\] \\(SS_{total}\\) is the same in both and \\(SS_{RM} = SS_{RM}\\) so what we are doing is splitting up the \\(SS_w\\) into \\(SS_{sub} + SS_{inter}\\) where only the \\(SS_{inter}\\) is the error term now. This means we have more power with the same amount of data. Let’s now plot this using a spaghetti plot. d %&gt;% ggplot(aes(word_type, words_recalled, group = ID)) + geom_line() + geom_point() The output provides us with a bit of an understanding of why there is not a significant effect of word_type. In addition to a spaghetti plot, it is often useful to show what the overall repeated measure factor is doing, not the individuals (especially if your sample size is larger than 20). To do that, we can use: oneway %&gt;% emmeans::emmip(~ word_type) Although there is a pattern here, we need to consider the scale. Looking at the spaghetti plot, we have individuals that range from 5 to 20 so a difference of 2 or 3 is not large. However, it is clear that a pattern may exist and so we should probably investigate this further, possibly with a larger sample size. 7.3 Another Example - Weight Loss Contrived data on weight loss and self esteem over three months, for three groups of individuals: Control, Diet and Diet + Exercise. The data constitute a double-multivariate design. 7.3.1 Restructure the data from wide to long format Wide format head(carData::WeightLoss, n = 6) group wl1 wl2 wl3 se1 se2 se3 1 Control 4 3 3 14 13 15 2 Control 4 4 3 13 14 17 3 Control 4 3 1 17 12 16 4 Control 3 2 1 11 11 12 5 Control 5 3 2 16 15 14 6 Control 6 5 4 17 18 18 Restructure WeightLoss_long &lt;- carData::WeightLoss %&gt;% dplyr::mutate(id = row_number() %&gt;% factor()) %&gt;% tidyr::gather(key = var, value = value, starts_with(&quot;wl&quot;), starts_with(&quot;se&quot;)) %&gt;% tidyr::separate(var, sep = 2, into = c(&quot;measure&quot;, &quot;month&quot;)) %&gt;% tidyr::spread(key = measure, value = value) %&gt;% dplyr::select(id, group, month, wl, se) %&gt;% dplyr::mutate_at(vars(id, month), factor) %&gt;% dplyr::arrange(id, month) Long format head(WeightLoss_long, n = 20) id group month wl se 1 1 Control 1 4 14 2 1 Control 2 3 13 3 1 Control 3 3 15 4 2 Control 1 4 13 5 2 Control 2 4 14 6 2 Control 3 3 17 7 3 Control 1 4 17 8 3 Control 2 3 12 9 3 Control 3 1 16 10 4 Control 1 3 11 11 4 Control 2 2 11 12 4 Control 3 1 12 13 5 Control 1 5 16 14 5 Control 2 3 15 15 5 Control 3 2 14 16 6 Control 1 6 17 17 6 Control 2 5 18 18 6 Control 3 4 18 19 7 Control 1 6 17 20 7 Control 2 5 16 Summary table WeightLoss_long %&gt;% dplyr::group_by(group, month) %&gt;% furniture::table1(wl, se) ─────────────────────────────────────────────────────────────────────────────────────────────────────── group, month Control-1 Diet-1 DietEx-1 Control-2 Diet-2 DietEx-2 n = 12 n = 12 n = 10 n = 12 n = 12 n = 10 wl 4.5 (1.0) 5.3 (1.4) 6.2 (2.3) 3.3 (1.1) 3.9 (1.4) 6.1 (1.4) se 14.8 (1.9) 14.8 (2.4) 15.2 (1.3) 14.3 (1.9) 13.8 (2.8) 13.3 (1.9) Control-3 Diet-3 DietEx-3 n = 12 n = 12 n = 10 2.1 (1.2) 2.2 (1.1) 2.2 (1.2) 15.1 (2.4) 16.2 (2.5) 17.6 (1.0) ─────────────────────────────────────────────────────────────────────────────────────────────────────── carData::WeightLoss %&gt;% dplyr::group_by(group) %&gt;% furniture::table1(wl1, wl2, wl3, se1, se2, se3) ────────────────────────────────────── group Control Diet DietEx n = 12 n = 12 n = 10 wl1 4.5 (1.0) 5.3 (1.4) 6.2 (2.3) wl2 3.3 (1.1) 3.9 (1.4) 6.1 (1.4) wl3 2.1 (1.2) 2.2 (1.1) 2.2 (1.2) se1 14.8 (1.9) 14.8 (2.4) 15.2 (1.3) se2 14.3 (1.9) 13.8 (2.8) 13.3 (1.9) se3 15.1 (2.4) 16.2 (2.5) 17.6 (1.0) ────────────────────────────────────── Raw data plot (exploratory) WeightLoss_long %&gt;% tidyr::gather(key = measure, value = value, wl, se) %&gt;% dplyr::mutate(measure = fct_recode(measure, &quot;Weight Loss, lb&quot; = &quot;wl&quot;, &quot;Self Esteem Rating&quot; = &quot;se&quot;)) %&gt;% ggplot(aes(x = month, y = value %&gt;% as.numeric %&gt;% jitter, group = id)) + facet_grid(measure ~ group, scale = &quot;free_y&quot;, switch = &quot;y&quot;) + geom_line() + theme_bw() + labs(x = &quot;Time, months&quot;, y = &quot;Measurement Value&quot;, title = &quot;Person Profile Plot&quot;, subtitle = &quot;Raw Data&quot;) 7.3.2 Does weight long change over time? Fit the model fit_wl &lt;- WeightLoss_long %&gt;% afex::aov_4(wl ~ 1 + (month|id), data = .) Brief output - uses the Greenhouse-Geisser correction for violations of sphericity (by default) fit_wl Anova Table (Type 3 tests) Response: wl Effect df MSE F ges p.value 1 month 2.00, 65.94 1.08 80.31 *** .427 &lt;.001 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;+&#39; 0.1 &#39; &#39; 1 Sphericity correction method: GG Lots more output summary(fit_wl) Univariate Type III Repeated-Measures ANOVA Assuming Sphericity Sum Sq num Df Error SS den Df F value Pr(&gt;F) (Intercept) 1584.35 1 162.314 33 322.115 &lt; 2.2e-16 *** month 173.88 2 71.451 66 80.308 &lt; 2.2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Mauchly Tests for Sphericity Test statistic p-value month 0.99908 0.98539 Greenhouse-Geisser and Huynh-Feldt Corrections for Departure from Sphericity GG eps Pr(&gt;F[GG]) month 0.99908 &lt; 2.2e-16 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 HF eps Pr(&gt;F[HF]) month 1.063446 2.090759e-18 To force no GG correction: fit_wl_noGG &lt;- WeightLoss_long %&gt;% afex::aov_4(wl ~ 1 + (month|id), data = ., anova_table = list(correction = &quot;none&quot;)) fit_wl_noGG Anova Table (Type 3 tests) Response: wl Effect df MSE F ges p.value 1 month 2, 66 1.08 80.31 *** .427 &lt;.001 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;+&#39; 0.1 &#39; &#39; 1 To request BOTH effect sizes: partial eta squared and generalized eta squared fit_wl_2es &lt;- WeightLoss_long %&gt;% afex::aov_4(wl ~ 1 + (month|id), data = ., anova_table = list(es = c(&quot;ges&quot;, &quot;pes&quot;))) fit_wl_2es Anova Table (Type 3 tests) Response: wl Effect df MSE F ges pes p.value 1 month 2.00, 65.94 1.08 80.31 *** .427 .709 &lt;.001 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;+&#39; 0.1 &#39; &#39; 1 Sphericity correction method: GG To force no GG correction AND request BOTH effect sizes fit_wl_noGG &lt;- WeightLoss_long %&gt;% afex::aov_4(wl ~ 1 + (month|id), data = ., anova_table = list(correction = &quot;none&quot;, es = c(&quot;ges&quot;, &quot;pes&quot;))) fit_wl_noGG Anova Table (Type 3 tests) Response: wl Effect df MSE F ges pes p.value 1 month 2, 66 1.08 80.31 *** .427 .709 &lt;.001 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;+&#39; 0.1 &#39; &#39; 1 Estimated marginal means fit_wl %&gt;% emmeans::emmeans(~ month) month emmean SE df lower.CL upper.CL X1 5.29 0.288 33 4.71 5.88 X2 4.35 0.295 33 3.75 4.95 X3 2.18 0.196 33 1.78 2.57 Confidence level used: 0.95 pairwise post hoc fit_wl %&gt;% emmeans::emmeans(~ month) %&gt;% pairs(adjust = &quot;none&quot;) contrast estimate SE df t.ratio p.value X1 - X2 0.941 0.250 33 3.771 0.0006 X1 - X3 3.118 0.256 33 12.178 &lt;.0001 X2 - X3 2.176 0.251 33 8.656 &lt;.0001 means plot fit_wl %&gt;% emmeans::emmip( ~ month) "],["mixed-design-anova.html", "8 Mixed Design ANOVA 8.1 Tutorial - Fitting Mixed Design ANOVA Models with afex::aov_4() 8.2 Words Recalled Data Example (Chapter 16, section A) 8.3 Conclusion", " 8 Mixed Design ANOVA Required Packages library(tidyverse) # Loads several very helpful &#39;tidy&#39; packages library(furniture) # Nice tables (by our own Tyson Barrett) library(afex) # needed for ANOVA, emmeans is loaded automatically. library(multcomp) # for advanced control for multiple testing/Type 1 error 8.1 Tutorial - Fitting Mixed Design ANOVA Models with afex::aov_4() The aov_4() function from the afex package fits ANOVA models (oneway, two-way, repeated measures, and mixed design). It needs at least two arguments: formula: continuous_var ~ group_var + (RM_var|id_var) one observation per subject for each level of the RMvar, so each id_var has multiple lines for each subject, each subject can only belong to exactly one group./ dataset: data = . we use the period to signify that the datset is being piped from above Here is an outline of what your syntax should look like when you fit and save a Mixed ANOVA. Of course you will replace the dataset name and the variable names, as well as the name you are saving it as. NOTE: The aov_4() function works on data in LONG format only. Each observation needs to be on its one line or row with seperate variables for the group membership (categorical factor or fct) and the continuous measurement (numberic or dbl). # RM ANOVA: fit and save aov_name &lt;- data_name %&gt;% afex::aov_4(continuous_var ~ group_var + (RM_var|id_var), data = .) 8.2 Words Recalled Data Example (Chapter 16, section A) 8.2.1 Data Prep I input the data as a tribble which saves it as a data.frame and then cleaned up a few of the important variables. d &lt;- tibble::tribble( ~ID, ~depression, ~word_type, ~words_recalled, 1, 0, 1, 20, 2, 0, 1, 16, 3, 0, 1, 8, 4, 1, 1, 17, 5, 1, 1, 15, 6, 1, 1, 10, 1, 0, 2, 21, 2, 0, 2, 18, 3, 0, 2, 7, 4, 1, 2, 15, 5, 1, 2, 10, 6, 1, 2, 4, 1, 0, 3, 17, 2, 0, 3, 11, 3, 0, 3, 4, 4, 1, 3, 18, 5, 1, 3, 13, 6, 1, 3, 10) %&gt;% mutate(depression = factor(depression, labels = c(&quot;Not Depressed&quot;, &quot;Depressed&quot;))) %&gt;% mutate(word_type = factor(word_type, labels = c(&quot;Neutral&quot;, &quot;Positive&quot;, &quot;Negative&quot;))) d # A tibble: 18 × 4 ID depression word_type words_recalled &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; 1 1 Not Depressed Neutral 20 2 2 Not Depressed Neutral 16 3 3 Not Depressed Neutral 8 4 4 Depressed Neutral 17 5 5 Depressed Neutral 15 6 6 Depressed Neutral 10 7 1 Not Depressed Positive 21 8 2 Not Depressed Positive 18 9 3 Not Depressed Positive 7 10 4 Depressed Positive 15 11 5 Depressed Positive 10 12 6 Depressed Positive 4 13 1 Not Depressed Negative 17 14 2 Not Depressed Negative 11 15 3 Not Depressed Negative 4 16 4 Depressed Negative 18 17 5 Depressed Negative 13 18 6 Depressed Negative 10 8.2.2 One-Way RM ANOVA First, let’s ignore the depression variable and just look at the repeated measures. We do this by using afex::aov_4() and then the summary() functions as shown below. oneway &lt;- d %&gt;% afex::aov_4(words_recalled ~ 1 + (word_type|ID), data = .) summary(oneway) Univariate Type III Repeated-Measures ANOVA Assuming Sphericity Sum Sq num Df Error SS den Df F value Pr(&gt;F) (Intercept) 3042.00 1 381.33 5 39.8864 0.001466 ** word_type 16.33 2 68.33 10 1.1951 0.342453 --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Mauchly Tests for Sphericity Test statistic p-value word_type 0.2134 0.045538 Greenhouse-Geisser and Huynh-Feldt Corrections for Departure from Sphericity GG eps Pr(&gt;F[GG]) word_type 0.55972 0.3282 HF eps Pr(&gt;F[HF]) word_type 0.6077293 0.3309148 Here, we see a number of pieces of information, including the sums of squares, F-statistic, and p-value. The p-value suggests that there is not an effect of word_type here (p = .342). Let’s plot this using a spaghetti plot. d %&gt;% ggplot(aes(word_type, words_recalled, group = ID)) + geom_line() + geom_point() But we wonder if depression has an effect on the number of words recalled, and it may interact with word_type. Let’s see what that looks like. d %&gt;% ggplot(aes(word_type, words_recalled, group = ID, color = depression, shape = depression, linetype = depression)) + geom_line() + geom_point() + facet_wrap(~depression) Definitely looks like the effect of word_type depends on whether the individual has depression or not. To add a between subjects factor to a repeated measures ANOVA, we are now doing mixed ANOVA (both between and within subjects factors). 8.2.3 Mixed ANOVA To run a mixed ANOVA, use afex::aov_4() and then the summary() functions again but this type with the between subjects factor included. mixed_anova &lt;- d %&gt;% afex::aov_4(words_recalled ~ depression + (word_type|ID), data = .) summary(mixed_anova) Univariate Type III Repeated-Measures ANOVA Assuming Sphericity Sum Sq num Df Error SS den Df F value Pr(&gt;F) (Intercept) 3042.00 1 375.78 4 32.3808 0.0047104 ** depression 5.56 1 375.78 4 0.0591 0.8198275 word_type 16.33 2 11.56 8 5.6538 0.0294740 * depression:word_type 56.78 2 11.56 8 19.6538 0.0008178 *** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Mauchly Tests for Sphericity Test statistic p-value word_type 0.81657 0.73788 depression:word_type 0.81657 0.73788 Greenhouse-Geisser and Huynh-Feldt Corrections for Departure from Sphericity GG eps Pr(&gt;F[GG]) word_type 0.845 0.03934 * depression:word_type 0.845 0.00183 ** --- Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 HF eps Pr(&gt;F[HF]) word_type 1.396104 0.0294739587 depression:word_type 1.396104 0.0008177732 The output provides us with a clear significant interaction shown in the first table. Our previous plot helps illustrate what this interaction is telling us about the patterns. However, it is often useful to show what the groups are doing, not the individuals (especially if your sample size is larger than 20). To do that, we can use: mixed_anova %&gt;% emmeans::emmip(depression ~ word_type) From this, we can tell that there is very little difference with neutral words, but large differences for positive and negative words. Specifically, depressed individuals struggle much more at recalling positive words than non-depressed individuals and depressed individuals do better at recalling negative words than non-depressed individuals. 8.3 Conclusion Overall, this is a good approach to using mixed ANOVA: Look at the repeated measures first, and then, Include any potentially important between-subjects factors. "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
